
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>sequence-modelling &#8212; sequence modelling 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="sequence-modelling">
<h1>sequence-modelling<a class="headerlink" href="#sequence-modelling" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-qdhmm"></span><p>Created on Thu May 30 15:38:44 2013</p>
<p>&#64;author: nbhushan</p>
<dl class="py class">
<dt class="sig sig-object py" id="qdhmm.QDHMM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">qdhmm.</span></span><span class="sig-name descname"><span class="pre">QDHMM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zeta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">O</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM" title="Permalink to this definition">¶</a></dt>
<dd><p>The QDHMM object.</p>
<dl class="simple">
<dt>p<span class="classifier">float</span></dt><dd><p>initial probability distribution for the active state.</p>
</dd>
<dt>zeta<span class="classifier">float</span></dt><dd><p>probability of self transitions in active state.</p>
</dd>
<dt>eta<span class="classifier">float</span></dt><dd><p>probability of self transitions in inactive state.</p>
</dd>
<dt>O<span class="classifier">object</span></dt><dd><p>QDHMM Emission Model</p>
</dd>
</dl>
<p>The QDHMM is an extension to a standard HMM.</p>
<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute alpha (forward) values.</p>
<blockquote>
<div><p>alpha [i,n] =  joint probability of being in state i,
after observing 1..N observations.   .</p>
</div></blockquote>
<dl class="simple">
<dt>B<span class="classifier">ndarray</span></dt><dd><p>The observation probability matrix.</p>
</dd>
</dl>
<dl class="simple">
<dt>alphahat<span class="classifier">ndarray</span></dt><dd><p>The scaled alpha values.</p>
</dd>
<dt>c<span class="classifier">ndarray</span></dt><dd><p>The scaling factors.</p>
</dd>
</dl>
<p>Refer to Rabiner’s paper <a href="#id9"><span class="problematic" id="id1">[1]_</span></a> for the scaling factors used here.</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>Rabiner, L. A tutorial on hidden Markov models and selected
applications in speech recognition Proceedings of the IEEE,
1989, 77, 257-286.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.beta">
<span class="sig-name descname"><span class="pre">beta</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute beta (backward) values.</p>
<blockquote>
<div><p>beta [i,n] =  conditional probability generating observations
Y_n+1..Y_N, given Z_n.</p>
</div></blockquote>
<dl class="simple">
<dt>B<span class="classifier">ndarray</span></dt><dd><p>The observation probability matrix.</p>
</dd>
<dt>c<span class="classifier">ndarray</span></dt><dd><p>The scaling factors obtained from the alpha computation</p>
</dd>
</dl>
<dl class="simple">
<dt>betahat<span class="classifier">ndarray</span></dt><dd><p>The scaled beta values.</p>
</dd>
</dl>
<p>DO NOT call the beta function before calling the alpha function.
Refer to Rabiner’s paper <a href="#id10"><span class="problematic" id="id3">[1]_</span></a> for the scaling factors used here.</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets">1</span></dt>
<dd><p>Rabiner, L. A tutorial on hidden Markov models and selected
applications in speech recognition Proceedings of the IEEE,
1989, 77, 257-286.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.buildTransmat">
<span class="sig-name descname"><span class="pre">buildTransmat</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.buildTransmat" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the sparse transition matrix.</p>
<dl class="simple">
<dt>A<span class="classifier">scipy.sparse.csr_matrix</span></dt><dd><p>The sparse transition matrix.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.gammaKsi">
<span class="sig-name descname"><span class="pre">gammaKsi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">B</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.gammaKsi" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute gamma (posterior distribution) values.</p>
<blockquote>
<div><p>gamma [i,n] =  conditional probability of the event state ‘i’
at time ‘n’, given the complete observation sequence.</p>
</div></blockquote>
<dl class="simple">
<dt>B<span class="classifier">ndarray</span></dt><dd><p>The observation probability matrix.</p>
</dd>
</dl>
<dl class="simple">
<dt>llh<span class="classifier">float</span></dt><dd><p>The normalized log-likelihood.</p>
</dd>
<dt>gamma<span class="classifier">ndarray</span></dt><dd><p>The posterior distribution.</p>
</dd>
<dt>float</dt><dd><p>The number of tranisitions into the active state.</p>
</dd>
<dt>float</dt><dd><p>The number of transitions into the inactive states.</p>
</dd>
</dl>
<p>Ksi is the joint succesive posterior distrbution.
ksi[n,i,j]  = joint posterior probability of two succesive hidden
states ‘i’ and ‘j’ at time ‘n’.
In the QDHMM, Ksi is too large to fit in contiguous memory [N,K,K].
Hence we estimate Ksi at every time step n, and store the relevant
parameters required for the computation and zeta and eta
(the transition parameters)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.qdhmmFit">
<span class="sig-name descname"><span class="pre">qdhmmFit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxiter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metaheuristic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'local'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.qdhmmFit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Fit the QDHMM to the given data using the (adapted Baum-Welch)</dt><dd><p>EM algorithm.</p>
</dd>
</dl>
<dl class="simple">
<dt>obs<span class="classifier">list</span></dt><dd><p>The list of observations sequences where every sequence is a
ndarray. The sequences can be of different length, but
the dimension of the features needs to be identical.</p>
</dd>
<dt>maxiter<span class="classifier">int, optional</span></dt><dd><p>The maximum number of iterations of the EM algorithm. Default = 50.</p>
</dd>
<dt>epsilon<span class="classifier">float, optional</span></dt><dd><p>The minimum allowed threshold in the variation of the log-likelihood
between succesive iterations of the EM algorithm. Once the variation
exceeds ‘epsilon’ the algorithm is said to have converged.
Default = 1e-6.</p>
</dd>
<dt>debug<span class="classifier">bool, optional</span></dt><dd><p>Display verbose On/off.</p>
</dd>
<dt>metaheuristic<span class="classifier">{‘local’, ‘sa’, ‘genetic’}, optional</span></dt><dd><p>The meta-heuristic to be used to solve the objective in the M-step.
‘local’ is simple local search. ‘genetic’ is genetic algorithm and
‘sa’ is simulated annealing.</p>
</dd>
</dl>
<dl class="simple">
<dt>float</dt><dd><p>The normalized log-likelihood.</p>
</dd>
<dt>list</dt><dd><p>The list of log-likelihoods for each iteration of the EM algorithm.
To check for monotonicity of the log-likelihoods.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates an observation sequence of length N.</p>
<dl class="simple">
<dt>dim<span class="classifier">int</span></dt><dd><p>The dimension of the data (univariate=1, etc..).</p>
</dd>
<dt>N<span class="classifier">int</span></dt><dd><p>The length of the observation sequence.</p>
</dd>
</dl>
<dl class="simple">
<dt>obs<span class="classifier">ndarray</span></dt><dd><p>An array of N observations.</p>
</dd>
<dt>zes<span class="classifier">ndarray</span></dt><dd><p>The state sequence that generated the data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="qdhmm.QDHMM.viterbi">
<span class="sig-name descname"><span class="pre">viterbi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#qdhmm.QDHMM.viterbi" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes Most probable path based on Viterbi algorithm.</p>
<blockquote>
<div><p>Most probable state sequence = argmax_z P(Z|X)</p>
</div></blockquote>
<dl class="simple">
<dt>obs<span class="classifier">array_like</span></dt><dd><p>Observation sequence.</p>
</dd>
</dl>
<dl class="simple">
<dt>path<span class="classifier">ndarray</span></dt><dd><p>The Viterbi decoded state sequence.</p>
</dd>
</dl>
<p>Refer to Rabiner’s paper <a href="#id11"><span class="problematic" id="id5">[1]_</span></a> or the original Viterbi paper <a class="footnote-reference brackets" href="#id8" id="id6">2</a>.</p>
<dl class="footnote brackets">
<dt class="label" id="id7"><span class="brackets">1</span></dt>
<dd><p>Rabiner, L. A tutorial on hidden Markov models and selected
applications in speech recognition Proceedings of the IEEE,
1989, 77, 257-286.</p>
</dd>
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>Viterbi, A. Error bounds for convolutional codes and an
asymptotically optimum decoding algorithm Information Theory,
IEEE Transactions on, 1967, 13, 260-269</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">sequence modelling</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=nbhushan&repo=Quasi-Deterministic-HMMs&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023 Nitin Bhushan.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/sequence_modelling.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>